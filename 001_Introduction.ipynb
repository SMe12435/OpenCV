{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[207, 208, 198],\n",
       "        [207, 208, 198],\n",
       "        [208, 209, 199],\n",
       "        ...,\n",
       "        [106, 127, 125],\n",
       "        [106, 127, 125],\n",
       "        [105, 126, 124]],\n",
       "\n",
       "       [[206, 207, 197],\n",
       "        [207, 208, 198],\n",
       "        [207, 208, 198],\n",
       "        ...,\n",
       "        [106, 127, 125],\n",
       "        [105, 126, 124],\n",
       "        [105, 126, 124]],\n",
       "\n",
       "       [[206, 207, 197],\n",
       "        [206, 207, 197],\n",
       "        [207, 208, 198],\n",
       "        ...,\n",
       "        [105, 126, 124],\n",
       "        [105, 126, 124],\n",
       "        [105, 126, 124]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[218, 209, 195],\n",
       "        [218, 209, 195],\n",
       "        [221, 210, 196],\n",
       "        ...,\n",
       "        [ 46,  87, 110],\n",
       "        [ 47,  85, 109],\n",
       "        [ 46,  84, 108]],\n",
       "\n",
       "       [[218, 209, 195],\n",
       "        [218, 209, 195],\n",
       "        [221, 210, 196],\n",
       "        ...,\n",
       "        [ 44,  85, 108],\n",
       "        [ 45,  83, 107],\n",
       "        [ 45,  83, 107]],\n",
       "\n",
       "       [[220, 209, 195],\n",
       "        [220, 209, 195],\n",
       "        [220, 209, 195],\n",
       "        ...,\n",
       "        [ 42,  83, 106],\n",
       "        [ 41,  82, 105],\n",
       "        [ 41,  82, 105]]], dtype=uint8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#images are rerpresented as multi-dimensional NumPy array with\n",
    "#dimensions height* columns\n",
    "\n",
    "image = cv2.imread(\"test.jpeg\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width=640, height=443, depth=3\n"
     ]
    }
   ],
   "source": [
    "(h,w,d) = image.shape\n",
    "#to extract the height width and depth\n",
    "print(\"width={}, height={}, depth={}\".format(w,h,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying the image\n",
    "cv2.imshow(\"Image\",image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"#757494\"><H3>Till here we loaded and displayed the picture</H3></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"#757494\"><H1>WHAT IS A PIXEL?</h1></font>\n",
    "<p>Images are made of pixels in a grid. A 640 x 480 image has 640 columns (the width) and 480 rows (the height). There are 640 * 480 = 307200  pixels in an image with those dimensions.</p>\n",
    "<p>Each pixel in a grayscale image has a value representing the shade of gray. In OpenCV, there are 256 shades of gray — from 0 to 255. So a grayscale image would have a grayscale value associated with each pixel.</p>\n",
    "<p>Pixels in a color image have additional information. There are several color spaces that you’ll soon become familiar with as you learn about image processing. For simplicity let’s only consider the RGB color space.\n",
    "    \n",
    "In OpenCV color images in the RGB (Red, Green, Blue) color space have a 3-tuple associated with each pixel: (B, G, R) .</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R=213, G=216, B=209\n"
     ]
    }
   ],
   "source": [
    "#accessing the RGB pixel located at x=50, y=100, NOTE - REMEMBER OPEN CV TAKES BGR instead of RGB\n",
    "(B,G,R) = image[100,50] #here on this line we have taken 'y' before the 'x' value as images are stored in the form\n",
    "#of height(rows)xwidth(cols) i.e. Y*X!\n",
    "print(\"R={}, G={}, B={}\".format(R,G,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#array slicing and cropping i.e. extracting regions of intrest(ROI)\n",
    "#let's extract 100*100 pixel square ROI from the input image\n",
    "roi = image[60:160,320:420]  #image[startY:endY,startX:endX]\n",
    "cv2.imshow(\"Region of Intrest\", roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now resizing image, not taking aspect ratio into count\n",
    "resized = cv2.resize(image,(200,200))\n",
    "cv2.imshow(\"Here's the resized image\",resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizing image taking aspect ratio into count\n",
    "#taking width as 300 and it will automatically give the aspect ratio\n",
    "r = 300.0/w  #\n",
    "dim = (300, int(h*r))\n",
    "resized = cv2.resize(image,dim)\n",
    "cv2.imshow(\"resized with ratio in mind\",resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for that we have imutils function already defined.\n",
    "resized = imutils.resize(image,width=300)\n",
    "cv2.imshow(\"resized image\",resized)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotating the image by 45 degrees\n",
    "#for that we need to compute the center of the image\n",
    "#then we will have to construct the rotation matrix\n",
    "#then finally we will apply affine warp\n",
    "\n",
    "center =(w//2,h//2)\n",
    "M = cv2.getRotationMatrix2D(center,-45,1.0)\n",
    "rotated = cv2.warpAffine(image,M,(w,h))\n",
    "cv2.imshow(\"Rotated Image\",rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same can be done with imutils library\n",
    "rotated = imutils.rotate(image, -45)\n",
    "cv2.imshow(\"Rotated Image\",rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Here on rotating we found that our image was clipped</h4>\n",
    "<p>So we will use an imutils function in order to overcome that problem</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rotatinf without the image clipping\n",
    "rotated = imutils.rotate_bound(image,-45)\n",
    "cv2.imshow(\"Rotated Image\",rotated)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Image smoothing</h3>\n",
    "<p>In many image processing pipelines, we must blur an image to reduce high-frequency noise, making it easier for our algorithms to detect and understand the actual contents of the image rather than just noise that will “confuse” our algorithms.\n",
    "\n",
    "Refer here for more on blurrness - https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(image,(11,11),0)\n",
    "cv2.imshow(\"Bluured Image\",blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Drawing on an image</h3>\n",
    "<p>Before we move on with drawing on an image with OpenCV, take note that drawing operations on images are performed in-place. Therefore at the beginning of each code block, we make a copy of the original image storing the copy as output . We then proceed to draw on the image called output in-place so we do not destroy our original image.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are drawing a 2px thick rectangle\n",
    "output = image.copy()\n",
    "cv2.rectangle(output,(320,60),(420,160),(0,0,255),2) #topleft coordinate and then bottom right\n",
    "cv2.imshow(\"Rectangle\",output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drawing a solid circle at x = 300, y=150\n",
    "output = image.copy()\n",
    "cv2.circle(output,(300,150),20,(255,0,0),-1) #(imagesrc,location,thickness,color,-1 denotes solid)\n",
    "cv2.imshow(\"Circle\",output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we are drawing a 5px thick line\n",
    "output = image.copy()\n",
    "output = image.copy()\n",
    "cv2.line(output, (60, 20), (400, 200), (0, 0, 255), 5)\n",
    "cv2.imshow(\"Line\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw green text on the image\n",
    "output = image.copy()\n",
    "cv2.putText(output, \"LEARNING OPEN CV BITCH\", (10, 25), \n",
    "\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "cv2.imshow(\"Text\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
